from fastapi import FastAPI, APIRouter, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import os
import json
import logging
from config import settings

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Validate configuration
if not settings.validate():
    logger.error("âŒ Configuration validation failed!")
    if not settings.openai_api_key:
        logger.error("Reason: OPENAI_API_KEY environment variable is not set")
    elif settings.openai_api_key == "your-openai-api-key-here":
        logger.error("Reason: OPENAI_API_KEY is still the default value, please set a real API Key")
    logger.error("Please check .env file or environment variable configuration")
else:
    logger.info(f"âœ… Configuration validation passed (model: {settings.default_model})")

app = FastAPI(
    title="PPTist AI Backend",
    description="AI-powered PPT generation backend using LangChain and FastAPI",
    version="0.1.0"
)

# Configure CORS allowed origins
allowed_origins = [
    "http://localhost:3000",  # React development server
    "http://localhost:5173",  # Vite development server
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    "http://localhost:8080",  # Vue development server
    "http://127.0.0.1:8080",
    
]

# If in debug mode, allow all origins (development environment)
if settings.debug:
    allowed_origins = ["*"]
    logger.info("ğŸŒ CORS: Debug mode - allowing all origins")
else:
    logger.info(f"ğŸŒ CORS: Production mode - allowed origins: {allowed_origins}")

# Add CORS middleware configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Add request validation error handler
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle request validation errors, provide detailed error information"""
    logger.error(f"ğŸš« Request validation failed: {request.method} {request.url}")
    logger.error(f"ğŸš« Error details: {exc.errors()}")
    
    # Extract request body information
    try:
        body = await request.body()
        if body:
            logger.error(f"ğŸš« Request body: {body.decode('utf-8')}")
    except Exception:
        pass
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "Request parameter validation failed",
            "help": {
                "/tools/aippt_outline": "Required parameters: model, language, content",
                "/tools/aippt": "Required parameters: model, language, content"
            }
        }
    )

router = APIRouter()

# PPT outline generation template
outline_template = """You are the user's PPT outline assistant. Based on the topic below, produce a presentation outline.

Guidelines:
- Create between 2 and 6 chapters, with a hard maximum of 10.
- Each chapter should contain 1 to 10 sections and vary the number of sections when possible.
- Section bullet points must stay between 1 and 6 items.
- Do not include commentary or explanations outside the outline.

Output format:
# PPT Title
## Chapter name
### Section name
- Bullet point
- Bullet point
### Section name
- ...

Topic requirements: {content}
Language of the outline: {language}
"""

outline_prompt = PromptTemplate.from_template(outline_template)

# PPT cover page and contents page generation template
cover_contents_template = """
You are an expert PPT assistant. Using the supplied outline, create JSON for a cover page and a table of contents page.

Output requirements:
- Each page must be a standalone JSON object on a single line.
- Separate pages with two newline characters.
- Do not add commentary or explanations.

Important notes:
- Only generate a cover page ("cover") and a contents page ("contents").
- Keep each text field under 100 words while staying descriptive.

Example (each JSON object on one line):

{{"type": "cover", "data": {{ "title": "API Overview", "text": "Discover the key elements of interface design" }}}}

{{"type": "contents", "data": {{ "items": ["Definition", "Classification", "Design Principles"] }}}}

Language: {language}
Outline content: {content}
"""

cover_contents_prompt = PromptTemplate.from_template(cover_contents_template)

# PPT section content generation template
section_content_template = """
You are an expert PPT assistant. Using the chapter details below, create JSON for a transition page and detailed content pages.

Output requirements:
- Each page must be a standalone JSON object on a single line.
- Separate pages with two newline characters.
- Do not add commentary or explanations.

Important notes:
- Generate one transition page ("transition") per chapter.
- Generate one content page ("content") for every section within the chapter.
- Keep each text field under 100 words while remaining informative.

Example (each JSON object on one line):

{{"type": "transition", "data": {{ "title": "Interface Definition", "text": "Introducing the core meaning of interfaces" }}}}

{{"type": "content", "data": {{ "title": "Interface Definition", "items": [ {{ "title": "Concept", "text": "Interfaces describe behaviours without implementations." }}, {{ "title": "Role", "text": "They enable polymorphism and loose coupling." }} ] }}}}

Language: {language}
Chapter title: {section_title}
Chapter details: {section_content}
"""

section_content_prompt = PromptTemplate.from_template(section_content_template)



def build_outline_chain(model_name: str = None):
    """Build PPT outline generation chain"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key is not configured")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return outline_prompt | llm | StrOutputParser()


def build_cover_contents_chain(model_name: str = None):
    """Build cover page and contents page generation chain"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key is not configured")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return cover_contents_prompt | llm | StrOutputParser()


def build_section_content_chain(model_name: str = None):
    """Build section content generation chain"""
    if not settings.validate():
        raise HTTPException(status_code=500, detail="OpenAI API Key is not configured")
    
    model_config = settings.get_model_config(model_name)
    llm = ChatOpenAI(
        temperature=model_config["temperature"],
        model=model_config["model"],
        openai_api_key=model_config["openai_api_key"],
        openai_api_base=model_config["openai_api_base"]
    )
    return section_content_prompt | llm | StrOutputParser()




def parse_outline(content: str) -> dict:
    """Parse outline content, extract title and chapter information"""
    lines = content.strip().split('\n')
    result = {
        'title': '',
        'chapters': []
    }
    
    current_chapter = None
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        if line.startswith('# '):  # PPTæ ‡é¢˜
            result['title'] = line[2:].strip()
        elif line.startswith('## '):  # Chapter title
            if current_chapter:
                result['chapters'].append(current_chapter)
            current_chapter = {
                'title': line[3:].strip(),
                'sections': []
            }
            current_section = None
        elif line.startswith('### '):  # èŠ‚æ ‡é¢˜
            if current_chapter:
                current_section = {
                    'title': line[4:].strip(),
                    'items': []
                }
                current_chapter['sections'].append(current_section)
        elif line.startswith('- '):  # å†…å®¹é¡¹
            if current_section:
                current_section['items'].append(line[2:].strip())
    
    # Add the last chapter
    if current_chapter:
        result['chapters'].append(current_chapter)
    
    return result


# è¯·æ±‚æ¨¡å‹å®šä¹‰
class PPTOutlineRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., max_length=50, description="ç”Ÿæˆçš„è¦æ±‚ï¼Œä¸è¶…è¿‡50å­—")
    stream: bool = True


class PPTContentRequest(BaseModel):
    model: str = Field('gpt-4o-mini', description="ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o æˆ– gpt-4o-mini")
    language: str = Field(..., description="ç”Ÿæˆå†…å®¹çš„è¯­è¨€ï¼Œä¾‹å¦‚ ä¸­æ–‡ã€English")
    content: str = Field(..., description="PPTå¤§çº²å†…å®¹")
    stream: bool = True


# è·¯ç”±å®ç°
@router.post("/tools/aippt_outline")
async def generate_ppt_outline_stream(request: PPTOutlineRequest):
    """ç”ŸæˆPPTå¤§çº²ï¼ˆæµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“ æ”¶åˆ°å¤§çº²ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}, è¦æ±‚={request.content}")
    
    try:
        chain = build_outline_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºå¤§çº²ç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

    async def token_stream():
        try:
            logger.info("å¼€å§‹ç”ŸæˆPPTå¤§çº²...")
            async for chunk in chain.astream({
                "content": request.content,
                "language": request.language
            }):
                yield chunk
            logger.info("PPTå¤§çº²ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f"é”™è¯¯: {error_msg}"

    return StreamingResponse(token_stream(), media_type="text/event-stream")


@router.post("/tools/aippt")
async def generate_ppt_content_stream(request: PPTContentRequest):
    """ç”ŸæˆPPTå†…å®¹ï¼ˆåˆ†æ­¥éª¤æµå¼è¿”å›ï¼‰"""
    logger.info(f"ğŸ“„ æ”¶åˆ°å†…å®¹ç”Ÿæˆè¯·æ±‚: æ¨¡å‹={request.model}, è¯­è¨€={request.language}")
    logger.info(f"ğŸ“„ å¤§çº²å†…å®¹é•¿åº¦: {len(request.content)} å­—ç¬¦")
    
    # è§£æå¤§çº²
    try:
        outline_data = parse_outline(request.content)
        logger.info(f"ğŸ“„ è§£æå¤§çº²æˆåŠŸ: æ ‡é¢˜={outline_data['title']}, ç« èŠ‚æ•°={len(outline_data['chapters'])}")
    except Exception as e:
        logger.error(f"è§£æå¤§çº²å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=400, detail="å¤§çº²æ ¼å¼è§£æå¤±è´¥")
    
    # æ„å»ºç”Ÿæˆé“¾
    try:
        cover_contents_chain = build_cover_contents_chain(request.model)
        section_content_chain = build_section_content_chain(request.model)
    except HTTPException as e:
        logger.error(f"æ„å»ºç”Ÿæˆé“¾å¤±è´¥: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"æ„å»ºç”Ÿæˆé“¾å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
    
    async def structured_page_stream():
        page_count = 0
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µ
            logger.info("ğŸ  å¼€å§‹ç”Ÿæˆå°é¢é¡µå’Œç›®å½•é¡µ...")
            buffer = ""
            async for chunk in cover_contents_chain.astream({
                "language": request.language,
                "content": request.content
            }):
                buffer += chunk
                # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„é¡µé¢åˆ†éš”ç¬¦ "\n\n"
                while "\n\n" in buffer:
                    page_content, separator, rest_of_buffer = buffer.partition("\n\n")
                    if page_content.strip():
                        page_count += 1
                        logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆå°é¢/ç›®å½•ï¼‰")
                        yield page_content + separator
                    buffer = rest_of_buffer
            
            # å¤„ç†å‰©ä½™å†…å®¹
            if buffer.strip():
                page_count += 1
                logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆå°é¢/ç›®å½•æœ€åä¸€é¡µï¼‰")
                yield buffer + "\n\n"
            
            # ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¿‡æ¸¡é¡µå’Œå†…å®¹é¡µ
            for chapter_idx, chapter in enumerate(outline_data['chapters']):
                logger.info(f"ğŸ“– å¼€å§‹ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« : {chapter['title']}")
                
                # å‡†å¤‡ç« èŠ‚å†…å®¹å­—ç¬¦ä¸²
                section_content = f"## {chapter['title']}\n"
                for section in chapter['sections']:
                    section_content += f"### {section['title']}\n"
                    for item in section['items']:
                        section_content += f"- {item}\n"
                
                buffer = ""
                async for chunk in section_content_chain.astream({
                    "language": request.language,
                    "section_title": chapter['title'],
                    "section_content": section_content
                }):
                    buffer += chunk
                    # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„é¡µé¢åˆ†éš”ç¬¦ "\n\n"
                    while "\n\n" in buffer:
                        page_content, separator, rest_of_buffer = buffer.partition("\n\n")
                        if page_content.strip():
                            page_count += 1
                            logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç¬¬{chapter_idx + 1}ç« ï¼‰")
                            yield page_content + separator
                        buffer = rest_of_buffer
                
                # å¤„ç†å‰©ä½™å†…å®¹
                if buffer.strip():
                    page_count += 1
                    logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç¬¬{chapter_idx + 1}ç« æœ€åä¸€é¡µï¼‰")
                    yield buffer + "\n\n"
            
            # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»“æŸé¡µ
            logger.info("ğŸ¬ å¼€å§‹ç”Ÿæˆç»“æŸé¡µ...")
            page_count += 1
            logger.debug(f"ç”Ÿæˆç¬¬ {page_count} é¡µå†…å®¹ï¼ˆç»“æŸé¡µï¼‰")
            yield '{"type": "end"}'
            
            logger.info(f"PPTå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {page_count} é¡µ")
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            yield f'{{"error": "{error_msg}"}}'

    return StreamingResponse(structured_page_stream(), media_type="text/event-stream")


# æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "message": "PPTist AI Backend is running"}


# æ·»åŠ JSONæ–‡ä»¶è¯»å–ç«¯ç‚¹
@router.get("/data/{filename}.json")
async def get_json_file(filename: str):
    """è¯»å–templateç›®å½•ä¸‹çš„JSONæ–‡ä»¶"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = os.path.join("template", f"{filename}.json")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            logger.warning(f"ğŸ“ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ {filename}.json ä¸å­˜åœ¨")
        
        # è¯»å–JSONæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"ğŸ“„ æˆåŠŸè¯»å–æ–‡ä»¶: {filename}.json")
        return data
        
    except json.JSONDecodeError as e:
        logger.error(f"ğŸš« JSONæ ¼å¼é”™è¯¯: {filename}.json - {str(e)}")
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ {filename}.json æ ¼å¼é”™è¯¯")
    except Exception as e:
        logger.error(f"ğŸš« è¯»å–æ–‡ä»¶å¤±è´¥: {filename}.json - {str(e)}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")


# æ³¨å†Œè·¯ç”±
app.include_router(router)


# æ ¹è·¯å¾„
@app.get("/")
async def root():
    return {
        "message": "Welcome to PPTist AI Backend",
        "version": "0.1.0",
        "endpoints": {
            "outline": "/tools/aippt_outline",
            "content": "/tools/aippt",
            "health": "/health",
            "data": "/data/{filename}.json",
            "docs": "/docs"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    if not settings.validate():
        logger.error("âŒ å¯åŠ¨å¤±è´¥: OpenAI API Key is not configuredæˆ–æ— æ•ˆ")
        logger.error("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–åˆ›å»º .env æ–‡ä»¶")
        logger.error("å¯ä»¥å¤åˆ¶ .env.example ä¸º .env å¹¶ä¿®æ”¹å…¶ä¸­çš„ API Key")
        exit(1)
    
    logger.info(f"ğŸš€ å¯åŠ¨ PPTist AI Backend...")
    logger.info(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: http://{settings.host}:{settings.port}")
    logger.info(f"ğŸ“š API æ–‡æ¡£: http://{settings.host}:{settings.port}/docs")
    
    try:
        uvicorn.run(
            "main:app",  # ä½¿ç”¨å­—ç¬¦ä¸²å¯¼å…¥è·¯å¾„ä»¥æ”¯æŒ reload åŠŸèƒ½
            host=settings.host,
            port=settings.port,
            reload=settings.debug
        )
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error("è¯·æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨æˆ–å…¶ä»–å¯åŠ¨é—®é¢˜")
        raise
